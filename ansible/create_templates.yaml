- name: Copy over the templates needed for a deployment
  hosts: undercloud
#
# This playbook is intented to quickly create a base set of
# overcloud deployment templates.
#
# The variables are pretty straight-forward.
#
  vars_files:
    - vars/globals.yaml
    - vars/networking.yaml
    - vars/storage.yaml
    - vars/services.yaml
    - vars/nodes.yaml
    - vars/undercloud_services.yaml
  vars:
    - base_templates: "network-environment.yaml,network-isolation.yaml,storage-environment.yaml"
    - template_files: []
    - ironic_cleaning_network_name: baremetal
  tasks:
    - name: Check if undercloud is deployed
      shell: |
        [ -z "$( ip a s br-ctlplane 2>/dev/null)" ] && echo False || echo True
      register: undercloud_deployed
    - name: Set undercloud_deployed fact
      set_fact:
        undercloud_deployed: "{{ undercloud_deployed.stdout }}"
    - name: Add ceph-ansible (version 13+)
      yum:
        name: ceph-ansible
        state: latest
      become: true
      when: osp_version >= 13
    - name: Create the necessary templates directories if needed
      file:
        path: "{{ item }}"
        state: directory
        mode: 0755
      with_items:
        - "{{ stack_templates }}"
        - "{{ stack_templates }}/environments"
        - "{{ stack_templates }}/network/config/{{ nic_configs }}"
    - name: Create the node-info.yaml for the Overcloud Scale
      copy:
        content: |
          parameter_defaults:
        dest: "{{ stack_templates }}/node-info.yaml"
    - name: Configure the flavors for the nodes in node-info.yaml
      lineinfile:
        path: "{{ stack_templates }}/node-info.yaml"
        regexp: "{{ item.flavor_parameter }}"
        line: "  {{ item.flavor_parameter }}: {{ item.flavor }}"
      with_items: "{{ nodes }}"
      when: item.count > 0
    - name: Configure the count for the nodes in node-info.yaml
      lineinfile:
        path: "{{ stack_templates }}/node-info.yaml"
        regexp: "{{ item.count_parameter }}"
        line: "  {{ item.count_parameter }}: {{ item.count }}"
      with_items: "{{ nodes }}"
      when: item.count > 0
    - name: Clean out any entries where the count is now zero
      lineinfile:
        path: "{{ stack_templates }}/node-info.yaml"
        regexp: "({{ item.count_parameter }}|{{ item.flavor_parameter }})"
        state: absent
      with_items: "{{ nodes }}"
      when: item.count == 0
    - name: Get list of default template files to copy
      find:
        path: "{{ tripleo_heat_templates }}"
        patterns: "{{ base_templates }}"
        recurse: yes
      register: find_results
    - name: Copy in the necessary template files
      shell: | 
        #!/bin/bash
        if [[ "{{ item.path }}" =~ "{{ tripleo_heat_templates }}/ci/" ]]
        then
          echo "Skipping continuous integration directory."
        else
          DESTINATION_FILE=$(echo "{{ item.path }}" | sed 's|{{ tripleo_heat_templates }}|{{ stack_templates }}|g')
          mkdir -p $(echo ${DESTINATION_FILE} | xargs dirname)
          cp {{ item.path }} ${DESTINATION_FILE}
        fi
      with_items: "{{ find_results.files }}"
    - name: Copy roles_data.yaml if doing custom roles
      copy:
        remote_src: true
        src: "{{ tripleo_heat_templates }}/roles_data.yaml"
        dest: "{{ stack_templates }}"
        force: true
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
      with_items: "{{ nodes }}"
      when: undercloud_deployed and item.custom_role == "True" and item.count != 0
    - name: Check if we are using a custom roles_data.yaml
      stat:
        path: "{{ stack_templates }}/roles_data.yaml"
      register: custom_roles
    - name: Set default count for all roles to 0 (if needed)
      replace:
        path: "{{ stack_templates }}/roles_data.yaml"
        regexp: 'CountDefault: 1'
        replace: "CountDefault: 0"
      when: custom_roles.stat.exists 
    - name: Update roles_data (if needed)
      shell: |
        WORK_FILE=$(mktemp)
        ROLE_NAME=$(echo "{{ item.count_parameter }}" | sed 's/Count$//g')
        ROLES=$(echo {{ item.role_combine }} | sed 's/,/ /g')
        for ROLE in ${ROLES}
        do
          sed -n "/- name: ${ROLE}/,/^ *$/p" {{ stack_templates }}/roles_data.yaml > ${WORK_FILE}.${ROLE}
        done
        echo "" >> {{ stack_templates }}/roles_data.yaml
        echo "- name: ${ROLE_NAME}" >>{{ stack_templates }}/roles_data.yaml
        echo "  CountDefault: 0" >>{{ stack_templates }}/roles_data.yaml
        echo "  ServicesDefault:" >>{{ stack_templates }}/roles_data.yaml
        cat ${WORK_FILE}.* | grep 'OS::' | sort -u >>{{ stack_templates }}/roles_data.yaml
        echo "" >> {{ stack_templates }}/roles_data.yaml
        rm -f ${WORK_FILE}*
      with_items: "{{ nodes }}"
      when: custom_roles.stat.exists and item.custom_role == "True"
    - name: Copy fixed-ip-vips if needed (version 13+)
      copy:
        src: "{{ tripleo_heat_templates }}/environments/fixed-ip-vips.yaml"
        dest: "{{ stack_templates }}/environments/fixed-ip-vips.yaml"
      with_items: "{{ networks }}"
      when: item.static_vip == "True" and osp_version >= 13
    - name: Check if we have a fixed-ip-vips.yaml (version 13+)
      stat:
        path: "{{ stack_templates }}/environments/fixed-ip-vips.yaml"
      register: osp13_fixed_vips
    - name: Comment existing fixed IPs (version 13+)
      command: sed -e '/FixedIPs/ s/^#*/#/' -i {{ stack_templates }}/environments/fixed-ip-vips.yaml
      when: osp13_fixed_vips.stat.exists == True
    - name: Remove network_roles.yaml if it exists (version 13+)
      file:
        path: /home/{{ uc_user }}/templates/{{ item }}
        state: absent
      with_items:
        - network_data.yaml
    - name: Create network_roles.yaml (version 13+)
      shell: |
        #!/bin/bash
        NAME_LOWER=$(echo {{ item.network }} | tr '[:upper:]' '[:lower:]')
        case ${NAME_LOWER} in
          storagemgmt)
            NAME_LOWER="storage_mgmt"
            ;;
          internalapi)
            NAME_LOWER="internal_api"
            ;;
        esac

        HAS_VIP=$( echo {{ item.static_vip }} | tr '[:upper:]' '[:lower:]')
        NETWORK={{ item.network }}
        VLAN={{ item.vlan }}

        echo "- name : ${NETWORK}" >> /home/{{ uc_user }}/templates/network_data.yaml
        echo "  vip: ${HAS_VIP}" >> /home/{{ uc_user }}/templates/network_data.yaml
        if [[ "${HAS_VIP}" == "true" && -f /home/{{ uc_user }}/templates/environments/fixed-ip-vips.yaml ]]
        then
          VIP={{ item.vip }}
          if [[ "${NETWORK}" == "External" ]]
          then
            NETWORK="Public"
          fi
          sed -i "/${NETWORK}VirtualFixedIPs/d" /home/{{ uc_user }}/templates/environments/fixed-ip-vips.yaml
          echo "  ${NETWORK}VirtualFixedIPs: [{'ip_address':'${VIP}'}]" >> /home/{{ uc_user }}/templates/environments/fixed-ip-vips.yaml
        fi
        echo "  name_lower: ${NAME_LOWER}" >> /home/{{ uc_user }}/templates/network_data.yaml
        if [[ ! -z "${VLAN}" ]]
        then
          echo "  vlan: ${VLAN}" >> /home/{{ uc_user }}/templates/network_data.yaml
        fi
        echo "  ip_subnet: '{{ item.cidr }}'" >> /home/{{ uc_user }}/templates/network_data.yaml
        echo "  allocation_pools: {{ item.pool }}" >> /home/{{ uc_user }}/templates/network_data.yaml
        if [[ ! -z "{{ item.default_route }}" ]]
        then
          echo "  gateway_ip: {{ item.default_route }}" >> /home/{{ uc_user }}/templates/network_data.yaml
        fi
      with_items: "{{ networks }}"
      when: osp_version >= 13
    - name: Generate common templates (version 13+)
      shell: |
        #!/bin/bash
        DYNAMIC_FILES="environments/network-environment.yaml environments/network-isolation.yaml"
        DYNAMIC_DIRECTORIES="network network/config network/ports network/config/{{ nic_configs }}"
        WORK_DIRECTORY=$(mktemp -p /tmp -d ansible.generate_templates.XXXXXX)
        cd {{ tripleo_heat_templates }}
        cp -pR . ${WORK_DIRECTORY}
        cd {{ stack_templates }}
        cp -pR . ${WORK_DIRECTORY}
        cd ${WORK_DIRECTORY}
        tools/process-templates.py
        for FILE in ${DYNAMIC_FILES}
        do
          cp ${WORK_DIRECTORY}/${FILE} {{ stack_templates }}/${FILE}
        done
        for DIRECTORY in ${DYNAMIC_DIRECTORIES}
        do
          mkdir -p {{ stack_templates }}/${DIRECTORY}
          for FILE in $(find ${DIRECTORY} -maxdepth 1 -type f | grep -v \.j2)
          do
            cp -p ${FILE} {{ stack_templates }}/${DIRECTORY}
          done
        done
        mkdir -p {{ stack_templates }}/network/config 2>/dev/null
        cp -pR ${WORK_DIRECTORY}/network/config/* {{ stack_templates }}/network/config
        cd ~
        rm -rf ${WORK_DIRECTORY}
    - name: Create the services sub-directory under environments if needed.
      file:
        state: directory
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
        path: "{{ stack_templates }}/environments/services/"
      when: deploy_ironic and osp_version < 13
    - name: Copy ironic.yaml if deploying ironic in the overcloud
      copy:
        remote_src: true
        src: "{{ tripleo_heat_templates }}/environments/services/ironic.yaml"
        dest: "{{ stack_templates }}/environments/services/"
        force: true
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
      when: deploy_ironic and osp_version < 13
    - name: Obtain the controlplane netmask from undercloud.conf
      shell: "grep '^local_ip' /home/{{ uc_user }}/undercloud.conf | awk -F/ '{print $NF}'"
      register: control_plane_netmask
    - name: Obtain the controlplane IP address from undercloud.conf
      shell: "grep '^local_ip' /home/{{ uc_user }}/undercloud.conf | awk '{print $NF}' | awk -F/ '{print $1}'"
      register: control_plane_ip
    - name: Obtain the controlplane gateway address from undercloud.conf (version <13)
      shell: "grep '^network_gateway' /home/{{ uc_user }}/undercloud.conf | awk '{print $NF}'"
      register: control_plane_gw
      when: osp_version < 13
    - name: Obtain the controlplane gateway address from undercloud.conf (version 13+)
      shell: "grep '^gateway' /home/{{ uc_user }}/undercloud.conf | awk '{print $NF}'"
      register: control_plane_gw
      when: osp_version >= 13
    - name: Update ControlPlaneSubnetCidr in network-environment.yaml
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: 'ControlPlaneSubnetCidr:.*$'
        replace: "ControlPlaneSubnetCidr: '{{ control_plane_netmask.stdout }}'"
    - name: Update EC2MetadataIp in network-environment.yaml
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: 'EC2MetadataIp:.*$'
        replace: "EC2MetadataIp: {{ control_plane_ip.stdout }}"
    - name: Update ControlPlaneDefaultRoute in network-environment.yaml
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: 'ControlPlaneDefaultRoute:.*$'
        replace: "ControlPlaneDefaultRoute: {{ control_plane_gw.stdout }}"
    - name: Update networking cidr's in network-environment.yaml (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "{{ item.network }}NetCidr:.*"
        replace: "{{ item.network }}NetCidr: {{ item.cidr }}"
      with_items: "{{ networks }}"
      when: osp_version < 13
    - name: Update networking VLANs in network-environment.yaml (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "{{ item.network }}NetworkVlanID:.*"
        replace: "{{ item.network }}NetworkVlanID: {{ item.vlan }}"
      with_items: "{{ networks }}"
      when: item.vlan != '' and osp_version < 13
    - name: Update networking allocation pools in network-environment.yaml (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "{{ item.network }}AllocationPools:.*"
        replace: "{{ item.network }}AllocationPools: {{ item.pool }}"
      with_items: "{{ networks }}"
      when: osp_version < 13
    - name: Update networking external network default route in network-environment.yaml (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "{{ item.network }}InterfaceDefaultRoute.*"
        replace: "{{ item.network }}InterfaceDefaultRoute: {{ item.default_route }}"
      with_items: "{{ networks }}"
      when: item.network  == "External" and osp_version < 13
    - name: Update networking DNS servers in network-environment.yaml
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "DnsServers:.*"
        replace: "DnsServers: {{ dns_servers }}"
    - name: Update nic-configs location in network-environment.yaml
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "/single-nic-vlans/"
        replace: "/{{ nic_configs }}/"
    - name: Copy over the desired nic-configs
      copy:
        src: "{{ tripleo_heat_templates }}/network/config/{{ nic_configs }}"
        dest: "{{ stack_templates }}/network/config/"
      when: osp_version < 13
    - name: Update Cinder ISCSI backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "CinderEnableIscsiBackend:.*$"
        replace: "CinderEnableIscsiBackend: {{ item.iscsi }}"
      when: item.storage == "cinder"
      with_items: "{{ storage_config }}"
    - name: Update Cinder Ceph backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "CinderEnableRbdBackend:.*$"
        replace: "CinderEnableRbdBackend: {{ item.ceph }}"
      when: item.storage == "cinder"
      with_items: "{{ storage_config }}"
    - name: Update Cinder Backup backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "CinderBackupBackend:.*$"
        replace: "CinderBackupBackend: {{ item.backup }}"
      when: item.storage == "cinder"
      with_items: "{{ storage_config }}"
    - name: Update Nova ephemeral backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "NovaEnableRbdBackend:.*$"
        replace: "NovaEnableRbdBackend: {{ item.use_ceph }}"
      when: item.storage == "nova-ephemeral"
      with_items: "{{ storage_config }}"
    - name: Update Glance backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "GlanceBackend:.*$"
        replace: "GlanceBackend: {{ item.backend }}"
      when: item.storage == "glance"
      with_items: "{{ storage_config }}"
    - name: Update Gnocchi backend
      replace:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        regexp: "GnocchiBackend:.*$"
        replace: "GnocchiBackend: {{ item.backend }}"
      when: item.storage == "gnocchi"
      with_items: "{{ storage_config }}"
    - name: Create a default fact that we are not using Ceph
      set_fact:
        include_ceph: False
    - name: Update ceph fact if Cinder is uing Ceph
      set_fact:
        include_ceph: True
      with_items: "{{ storage_config }}"
      when: item.storage == "cinder" and item.ceph
    - name: Update ceph fact if Cinder Backup is uing Ceph
      set_fact:
        include_ceph: True
      with_items: "{{ storage_config }}"
      when: item.storage == "cinder" and item.backup == "ceph"
    - name: Update ceph fact if Nova-ephemeral is uing Ceph
      set_fact:
        include_ceph: True
      with_items: "{{ storage_config }}"
      when: item.storage == "nova-ephemeral" and item.use_ceph
    - name: Update ceph fact if Glance is uing Ceph
      set_fact:
        include_ceph: True
      with_items: "{{ storage_config }}"
      when: item.storage == "glance" and item.backend == "rbd"
    - name: Update ceph fact if Gnocchi is uing Ceph
      set_fact:
        include_ceph: True
      with_items: "{{ storage_config }}"
      when: item.storage == "gnocchi" and item.backend == "rbd"
    - debug:
        var: include_ceph
      when: include_ceph
    - name: Remove references to Ceph components from storage-environment.yaml if not using Ceph
      shell: |
        sed -i '/{{ item }}/d' {{ stack_templates }}/environments/storage-environment.yaml
      with_items: 
        - ceph-mgr.yaml
        - ceph-mon.yaml
        - ceph-osd.yaml
        - ceph-client.yaml
        - resource_registry
      when: not include_ceph
    - name: Add wipe-disk to storage-environment.yaml
      lineinfile:
        path: "{{ stack_templates }}/environments/storage-environment.yaml"
        state: present
        line: "  OS::TripleO::NodeUserData: {{ stack_templates }}/wipe-disks.yaml"
        regexp: ".* OS::TripleO::NodeUserData: {{ stack_templates }}/wipe-disks.yaml.*"
        insertafter: '.*resource_registry.*'
      when: include_ceph
    - name: Create wipe-disk.sh for Ceph
      copy:
        content: |
          #!/bin/bash
          if [[ `hostname` = *"ceph"* ]]
          then
            echo "Number of disks detected: $(lsblk -no NAME,TYPE,MOUNTPOINT | grep "disk" | awk '{print $1}' | wc -l)"
            for DEVICE in `lsblk -no NAME,TYPE,MOUNTPOINT | grep "disk" | awk '{print $1}'`
            do
              ROOTFOUND=0
              echo "Checking /dev/$DEVICE..."
              echo "Number of partitions on /dev/$DEVICE: $(expr $(lsblk -n /dev/$DEVICE | awk '{print $7}' | wc -l) - 1)"
              for MOUNTS in `lsblk -n /dev/$DEVICE | awk '{print $7}'`
              do
                if [ "$MOUNTS" = "/" ]
                then
                  ROOTFOUND=1
                fi
              done
              if [ $ROOTFOUND = 0 ]
              then
                echo "Root not found in /dev/${DEVICE}"
                echo "Wiping disk /dev/${DEVICE}"
                sgdisk -Z /dev/${DEVICE}
                sgdisk -g /dev/${DEVICE}
              else
                echo "Root found in /dev/${DEVICE}"
              fi
            done
          fi
        dest: "{{ stack_templates }}/wipe-disk.sh"
        force: true
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
      when: include_ceph
    - name: Create wipe-disks.yaml for Ceph
      copy:
        content: |
          heat_template_version: 2014-10-16
          
          description: >
            Wipe and convert all disks to GPT (except the disk containing the root file system)
          
          resources:
            userdata:
              type: OS::Heat::MultipartMime
              properties:
                parts:
                - config: {get_resource: wipe_disk}
          
            wipe_disk:
              type: OS::Heat::SoftwareConfig
              properties:
                config: {get_file: wipe-disk.sh}
          
          outputs:
            OS::stack_id:
              value: {get_resource: userdata}
        dest: "{{ stack_templates }}/wipe-disks.yaml"
        force: true
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
      when: include_ceph
    - name: Check if we are using a custom network-isolation.yaml
      stat:
        path: "{{ stack_templates }}/environments/network-isolation.yaml"
      register: custom_isolation
    - name: Update relative paths for network-isolation if it is being over-ridden (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-isolation.yaml"
        regexp: '\.\.\/network'
        replace: "{{ tripleo_heat_templates }}/network"
      when: custom_isolation.stat.exists == True and osp_version < 13
    - name: Create flavors for custom roles (if needed)
      shell: |
             source ~/stackrc >/dev/null 2>&1
             if [[ -z "$(openstack flavor list -c Name -f value | grep {{ item.flavor }})" ]]
             then
               openstack flavor create --ram 4096 --disk 40 --vcpus 1 --public {{ item.flavor }}
               openstack flavor set --property "cpu_arch"="x86_64" --property "capabilities:boot_option"="local" --property "capabilities:profile"="computeosd" computeosd
             fi
      with_items: "{{ nodes }}"
      when: undercloud_deployed and custom_roles.stat.exists and item.custom_role == "True"
    - name: Update network-isolation ports (if needed) (version <13)
      shell: |
        WORK_FILE=$(mktemp)
        ROLE_NAME=$(echo "{{ item.count_parameter }}" | sed 's/Count$//g')
        ROLES=$(echo {{ item.role_combine }} | sed 's/,/ /g')
        for ROLE in ${ROLES}
        do
          grep "${ROLE}::Ports" {{ stack_templates }}/environments/network-isolation.yaml | grep -v "^ *#">> ${WORK_FILE}
        done
        echo "" >>{{ stack_templates }}/environments/network-isolation.yaml
        echo "  # Port assignments for the ${ROLE_NAME} role" >>{{ stack_templates }}/environments/network-isolation.yaml
        for PORT_TYPE in $(cat ${WORK_FILE} | awk '{print $1}' | awk -F: '{print $9}' | sort -u)
        do
          PORT_FILE=""
          PORT_FILE=$(grep ${PORT_TYPE} ${WORK_FILE} | grep -v noop.yaml | head -1 | awk '{print $NF}' )
          if [[ -z "${PORT_FILE}" ]]
          then
            PORT_FILE=$(grep ${PORT_TYPE} ${WORK_FILE} | grep noop.yaml | head -1 | awk '{print $NF}' )
          fi
          echo "  OS::TripleO::${ROLE_NAME}::Ports::${PORT_TYPE}: ${PORT_FILE}" >>{{ stack_templates }}/environments/network-isolation.yaml
        done
      with_items: "{{ nodes }}"
      when: custom_isolation.stat.exists and custom_roles.stat.exists and item.custom_role == "True" and osp_version < 13
    - name: Update network-environment ports (if needed) (version <13)
      shell: |
        WORK_FILE=$(mktemp)
        ROLE_NAME=$(echo "{{ item.count_parameter }}" | sed 's/Count$//g')
        ROLES=$(echo {{ item.role_combine }} | sed 's/,/ /g')
        for ROLE in ${ROLES}
        do
          grep "${ROLE}::Ports" {{ stack_templates }}/environments/network-isolation.yaml | grep -v "^ *#">> ${WORK_FILE}
        done
        echo "" >>{{ stack_templates }}/environments/network-isolation.yaml
        echo "  # Port assignments for the ${ROLE_NAME} role" >>{{ stack_templates }}/environments/network-isolation.yaml
        for PORT_TYPE in $(cat ${WORK_FILE} | awk '{print $1}' | awk -F: '{print $9}' | sort -u)
        do
          PORT_FILE=""
          PORT_FILE=$(grep ${PORT_TYPE} ${WORK_FILE} | grep -v noop.yaml | head -1 | awk '{print $NF}' )
          if [[ -z "${PORT_FILE}" ]]
          then
            PORT_FILE=$(grep ${PORT_TYPE} ${WORK_FILE} | grep noop.yaml | head -1 | awk '{print $NF}' )
          fi
          echo "  OS::TripleO::${ROLE_NAME}::Ports::${PORT_TYPE}: ${PORT_FILE}" >>{{ stack_templates }}/environments/network-isolation.yaml
        done
      with_items: "{{ nodes }}"
      when: custom_isolation.stat.exists and custom_roles.stat.exists and item.custom_role == "True" and osp_version < 13
    - name: Copy YAML files for TLS configuration if using TLS
      copy:
        src: "{{ tripleo_heat_templates }}/{{ item }}"
        dest: "{{ stack_templates }}/{{ item }}"
      with_items: 
        - environments/enable-tls.yaml
        - environments/inject-trust-anchor.yaml
      when: ssl_config.enable_tls == "True"
    - name: Update relevant path names for TLS files
      replace:
        path: "{{ stack_templates }}/{{ item }}"
        regexp: '\.\.\/puppet/'
        replace: "{{ tripleo_heat_templates }}/puppet/"
      with_items: 
        - environments/enable-tls.yaml
        - environments/inject-trust-anchor.yaml
      when: ssl_config.enable_tls == "True"
    - name: Add cloud info to network-environment.yaml if using TLS
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "  {{ item.setting }}:.*$"
        line: "  {{ item.setting }}: {{ item.value }}"
      with_items:
        - { setting: "CloudName", value: "{{ ssl_config.cloud_name }}" }
        - { setting: "CloudDomain", value: "{{ ssl_config.cloud_domain }}" }
      when: ssl_config.enable_tls == "True"
    - name: Add TimeZone info to network-environment.yaml
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "  TimeZone:.*$"
        line: "  TimeZone: '{{ overcloud_timezone }}'"
    - name: Configure NTP Server
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "  NtpServer:.*$"
        line: "  NtpServer: {{ ntp_server }}"
    - name: Configure any static VIPs (version <13)
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "  {{ item.network }}VirtualFixedIPs:.*$"
        line: "  {{ item.network }}VirtualFixedIPs: [{'ip_address':'{{ item.vip }}'}]"
      with_items: "{{ networks }}"
      when: item.static_vip == "True" and osp_version < 13
    - name: Change the External VIP name from External to Public because it'd the only weird one (version <13)
      replace:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        regexp: "ExternalVirtualFixedIPs"
        replace: "PublicVirtualFixedIPs"
      when: osp_version < 13
    - name: Enable Fernet Tokens in the Overcloud (version <13)
      shell: |
        #!/bin/bash

        mkdir -p /home/{{ uc_user }}/fernet
        
        source /home/{{ uc_user }}/stackrc
        printf "Generating the fernet keys and tarring them up in /home/{{ uc_user }}/fernet.\n"
        sudo keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
        sudo tar -zcf /home/{{ uc_user }}/fernet/keystone-fernet-keys.tar.gz /etc/keystone/fernet-keys
        printf "DONE\n"
        
        printf "Remove existing swift overcloud-artifacts container (if it exists).\n"
        swift delete overcloud-artifacts
        printf "DONE\n"
        
        printf "Uploading the fernet keys to swift.\n"
        upload-swift-artifacts -f /home/{{ uc_user }}/fernet/keystone-fernet-keys.tar.gz --environment /home/{{ uc_user }}/fernet/deployment-artifacts.yaml
        printf "DONE\n"
        
        printf "creating ferent.yaml in $environment\n"

        echo 'parameter_defaults:' >/home/{{ uc_user }}/fernet/fernet.yaml
        echo '          controllerExtraConfig:' >>/home/{{ uc_user }}/fernet/fernet.yaml
        echo "            keystone::token_provider: 'fernet'" >>/home/{{ uc_user }}/fernet/fernet.yaml

        for YAML in fernet.yaml deployment-artifacts.yaml
        do
          cp /home/{{ uc_user }}/fernet/${YAML} {{ stack_templates }}/environments/
        done
      when: enable_fernet and osp_version < 13
    - name: Add bridge mappings for Ironic (version <13)
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        insertafter: NeutronNetworkVLANRanges
        line: '  NeutronBridgeMappings: datacentre:br-ex,baremetal:br-baremetal'
      when: deploy_ironic and osp_version < 13
    - name: Add flat network for Ironic (version <13)
      lineinfile:
        path: "{{ stack_templates }}/environments/network-environment.yaml"
        insertafter: NeutronBridgeMappings
        line: '  NeutronFlatNetworks: datacentre,baremetal'
      when: deploy_ironic and osp_version < 13
    - name: Generate ironic-config.yaml
      copy:
        content: |
          parameter_defaults:
          
              NovaSchedulerDefaultFilters:
                  - RetryFilter
                  - AggregateInstanceExtraSpecsFilter
                  - AvailabilityZoneFilter
                  - RamFilter
                  - DiskFilter
                  - ComputeFilter
                  - ComputeCapabilitiesFilter
                  - ImagePropertiesFilter
              IronicCleaningDiskErase: metadata
              ControllerExtraConfig:
                 ironic::conductor::cleaning_network: {{ ironic_cleaning_network_name }}
                 ironic::conductor::automated_clean: false
          
        dest: "{{ stack_templates }}/environments/ironic-config.yaml"
        owner: stack
        group: stack
        mode: u+rw,g+r,o+r
      when: deploy_ironic
    - name: Generate base {{ deploy_script }}
      copy:
        content: |
          #!/bin/bash
          cd ~{{ uc_user }}
          source ~/stackrc
          time openstack overcloud deploy --templates \
            -e {{ stack_templates }}/node-info.yaml \
            -e {{ stack_templates }}/environments/storage-environment.yaml \
            -e {{ stack_templates }}/environments/network-environment.yaml \
            -e {{ tripleo_heat_templates }}/environments/network-isolation.yaml \
            --log-file overcloud_deployment.log \
            --ntp-server {{ ntp_server }}
        dest: "{{ deploy_script }}"
        owner: stack
        group: stack
        mode: u+rwx,g+rx,o+rx
    - name: Add VIP Template to the overcloud-deploy.sh (version 13+)
      lineinfile:
        path: "{{ deploy_script }}"
        state: present
        line: "  -e {{ stack_templates }}/environments/fixed-ip-vips.yaml \\"
        regexp: ".*  -e {{ stack_templates }}/environments/fixed-ip-vips.yaml \\.*"
        insertafter: '.*network-environment.yaml.*'
      with_items: "{{ networks }}"
      when: item.static_vip and osp_version >= 13
    - name: Add network_data.yaml to the overcloud-deploy.sh (version 13+)
      lineinfile:
        path: "{{ deploy_script }}"
        state: present
        line: "  -n {{ stack_templates }}/network_data.yaml \\"
        regexp: ".*-n {{ stack_templates }}/network_data.yaml \\.*"
        insertafter: 'openstack overcloud deploy'
      when: osp_version >= 13
    - name: Add Fernet YAML's to overcloud-deploy.sh (if needed) (version <13)
      blockinfile:
        path: "{{ deploy_script }}"
        block: |2
            -e {{ stack_templates }}/environments/fernet.yaml \
            -e {{ stack_templates }}/environments/deployment-artifacts.yaml \
        marker: "  # {mark} ANSIBLE FERNET BLOCK"
        insertbefore: log-file overcloud_deployment.log
      when: osp_version < 13
    - name: Add roles_data.yaml if doing custom roles
      lineinfile:
        path: /home/{{ uc_user }}/overcloud-deploy.sh
        insertafter: openstack overcloud deploy
        line: '  -r {{ stack_templates }}/roles_data.yaml \'
      when: custom_roles.stat.exists 
    - name: Add Ironic YAML's to overcloud-deploy.sh (if needed)
      blockinfile:
        path: "{{ deploy_script }}"
        block: |2
            -e {{ stack_templates }}/environments/services/ironic.yaml \
            -e {{ stack_templates }}/environments/ironic-config.yaml \
        marker: "  # {mark} ANSIBLE IRONIC BLOCK"
        insertbefore: log-file overcloud_deployment.log
      when: deploy_ironic and osp_version < 13
    - name: List the baremetal nodes from stored in Ironic
      shell: |
        #!/bin/bash
        source ~/stackrc
        openstack baremetal node list -c Name -f value >/tmp/overcloud_baremetal.txt
        if [ ! -s /tmp/overcloud_baremetal.txt ]
        then
          rm /tmp/overcloud_baremetal.txt
        fi
    - name: Check if baremetal nodes exist in Ironic (file check)
      stat:
        path: /tmp/overcloud_baremetal.txt
      register: baremetal_nodes
    - name: Check if the nodes have been introspected (ceph)
      shell: | 
        #!/bin/bash
        source ~stack/stackrc
        WORK_DIRECTORY=$(mktemp -p /tmp -d ansible.check_introspecton.XXXXXX)
        for NODE in $(openstack baremetal node list -c Name -f value)
        do
          INTROSPECTION_STATUS=$(openstack baremetal introspection status -c finished -f value ${NODE} 2>/dev/null)
          if [[ -z "${INTROSPECTION_STATUS}" || "${INTROSPECTION_STATUS}" != "True" ]]
          then
            INTROSPECTION_STATUS="not_introspected"
          else
            INTROSPECTION_STATUS="introspected"
          fi
          NODE_TYPE="node"
          if [[ ! -z "$(openstack baremetal node show -c properties -f value ${NODE} | grep {{ ceph_node_capability }})" ]]
          then
            NODE_TYPE="CEPH"
          fi
          echo "${NODE}:${INTROSPECTION_STATUS}:${NODE_TYPE}" >>${WORK_DIRECTORY}/overcloud_baremetal.txt
        done
        CEPH_NODES=$(grep "CEPH" ${WORK_DIRECTORY}/overcloud_baremetal.txt | wc -l)
        CEPH_INTROSPECTED=$(grep ':introspected:CEPH' ${WORK_DIRECTORY}/overcloud_baremetal.txt | wc -l)
        if [[ ${CEPH_NODES} -gt 0 && ${CEPH_INTROSPECTED} -gt 0 && ${CEPH_NODES} -eq ${CEPH_INTROSPECTED} ]]
        then
          echo "true"
        else
          echo "false"
        fi
        rm -rf ${WORK_DIRECTORY} 2>/dev/null
      register: introspection_status
      when: ceph_configure_root_disk and baremetal_nodes.stat.exists and include_ceph and ceph_deployment == 'director'
    - name: Configure root_disk (if possible) (ceph)
      shell: | 
        #!/bin/bash
        source ~stack/stackrc
        WORK_DIRECTORY=$(mktemp -p /tmp -d ansible.configure_ceph_root_disk.XXXXXX)
        ROOT_DISK={{ ceph_root_disk }}
        CEPH_NODES=""
        for NODE in $(openstack baremetal node list -f value -c Name)
        do
          if [[ ! -z "$(openstack baremetal node show -c properties -f value ${NODE} | grep {{ ceph_node_capability }})" ]]
          then
            CEPH_NODES="${CEPH_NODES} ${NODE}"
            openstack baremetal introspection data save ${NODE} >${WORK_DIRECTORY}/${NODE}.introspection
          fi
        done

        ERROR_COUNT=0
        for NODE_NAME in ${CEPH_NODES}
        {
          if [[ ! -r ${WORK_DIRECTORY}/${NODE_NAME}.introspection ]]
          then
            ERROR_COUNT=$(( ${ERROR_COUNT} + 1 ))
          else
            DATA_FILE=${WORK_DIRECTORY}/${NODE_NAME}.introspection
            if [[ -z "$(grep ${ROOT_DISK} ${DATA_FILE})" ]]
            then
              ERROR_COUNT=$(( ${ERROR_COUNT} + 1 ))
            else
              WWN=$(cat ${DATA_FILE} | jq '.inventory.disks | .[] | select( .name | contains("{{ ceph_root_disk }}"))' | grep '"wwn"' | awk -F: '{print $2}' | sed 's/[", ]//g')
              SERIAL=$(cat ${DATA_FILE} | jq '.inventory.disks | .[] | select( .name | contains("{{ ceph_root_disk }}"))' | grep '"serial"' | awk -F: '{print $2}' | sed 's/[", ]//g')
              if [[ "${WWN}" == "null" ]]
              then
                openstack baremetal node set --property root_device="{'serial': '${SERIAL}'}" ${NODE_NAME}
              else
                openstack baremetal node set --property root_device="{'wwn': '${WWN}'}" ${NODE_NAME}
              fi
              openstack baremetal node show -c name -c properties ${NODE_NAME}
            fi
          fi
        }
        rm -rf ${WORK_DIRECTORY} 2>/dev/null
        exit ${ERROR_COUNT}
      when: ceph_configure_root_disk and baremetal_nodes.stat.exists and introspection_status.stdout == 'true' and include_ceph and ceph_deployment == 'director'
    - name: Create Ceph storage configuration (if needed) (version 13+)
      shell: | 
        #!/bin/bash
        CEPH_CUSTOM_CONFIG={{ stack_templates }}/ceph-custom-config.yaml
        echo "parameter_defaults:" >${CEPH_CUSTOM_CONFIG}
        echo "  CephConfigOverrides:" >>${CEPH_CUSTOM_CONFIG}
        echo "    mon_max_pg_per_osd: {{ ceph_mon_max_pg_per_osd }}" >>${CEPH_CUSTOM_CONFIG}
        echo "    journal_size: {{ ceph_journal_size }}" >>${CEPH_CUSTOM_CONFIG}
        echo "    osd_pool_default_size: {{ ceph_osd_pool_default_size }}" >>${CEPH_CUSTOM_CONFIG}
        echo "    osd_pool_default_min_size: {{ ceph_osd_pool_default_min_size }}" >>${CEPH_CUSTOM_CONFIG}
        echo "    osd_pool_default_pg_num: {{ ceph_osd_pool_default_pg_num }}" >>${CEPH_CUSTOM_CONFIG}
        echo "    osd_pool_default_pgp_num: {{ ceph_osd_pool_default_pgp_num }}" >>${CEPH_CUSTOM_CONFIG}
        echo "  CephAnsibleDisksConfig:" >>${CEPH_CUSTOM_CONFIG}
        echo "    dmcrypt: {{ ceph_encrypt_osd }}" >>${CEPH_CUSTOM_CONFIG}
      when: include_ceph and ceph_deployment == 'director' and osp_version >= 13
    - name: Add OSD's to the configuration file (version 13+)
      shell: |
        #!/bin/bash
        CEPH_CUSTOM_CONFIG={{ stack_templates }}/ceph-custom-config.yaml
        OSD={{ item.osd }}
        JOURNAL={{ item.journal }}
        if [[ ! -z "{{ item.journal }}" && -z "$(grep "    osd_scenario: non-collocated" ${CEPH_CUSTOM_CONFIG})" ]]
        then
          echo "    osd_scenario: non-collocated" >>${CEPH_CUSTOM_CONFIG}
        elif [[ -z "{{ item.journal }}" && -z "$(grep "    osd_scenario: collocated" ${CEPH_CUSTOM_CONFIG})" ]]
        then
          echo "    osd_scenario: collocated" >>${CEPH_CUSTOM_CONFIG}
        fi
        if [[ -z "$(grep "    devices:" ${CEPH_CUSTOM_CONFIG})" ]]
        then
          echo "    devices:" >>${CEPH_CUSTOM_CONFIG}
        fi
        echo "      - ${OSD}" >>${CEPH_CUSTOM_CONFIG}
      with_items: "{{ ceph_disks }}"
      when: include_ceph and ceph_deployment == 'director' and osp_version >= 13
    - name: Add Journal's to the configuration file (if needed) (version 13+)
      shell: |
        #!/bin/bash
        CEPH_CUSTOM_CONFIG={{ stack_templates }}/ceph-custom-config.yaml
        JOURNAL={{ item.journal }}
        if [[ -z "$(grep "    dedicated_devices:" ${CEPH_CUSTOM_CONFIG})" ]]
        then
          echo "    dedicated_devices:" >>${CEPH_CUSTOM_CONFIG}
        fi
        echo "      - ${JOURNAL}" >>${CEPH_CUSTOM_CONFIG}
      with_items: "{{ ceph_disks }}"
      when: include_ceph and ceph_deployment == 'director' and osp_version >= 13 and item.journal != ''
    - name: Add ceph configuration to the overcloud-deploy.sh (version 13+)
      lineinfile:
        path: "{{ deploy_script }}"
        state: present
        line: "  -e {{ stack_templates }}/ceph-custom-config.yaml \\"
        regexp: ".*-e {{ stack_templates }}/ceph-custom-config.yaml \\.*"
        insertafter: '.*storage-environment.yaml.*'
      when: include_ceph and ceph_deployment == 'director' and osp_version >= 13
    - name: Delete /home/{{ uc_user }}/configure_containers.sh if it exists
      file:
        path: /home/{{ uc_user }}/configure_containers.sh
        state: absent
    - name: Create /home/{{ uc_user }}/configure_containers.sh
      file:
        path: /home/{{ uc_user }}/configure_containers.sh
        state: touch
        owner: "{{ uc_user }}"
        group: "{{ uc_user }}"
        mode: 0755
      when: osp_version >= 12 and osp_version <= 13
    - name: Create script to perform necessary container generation (version 12-13)
      blockinfile:
        path: /home/{{ uc_user }}/configure_containers.sh
        block: |
          #!/bin/bash
          source /home/{{ uc_user }}/stackrc
          openstack overcloud container image prepare \
        marker: "  # {mark} ANSIBLE BLOCK SCRIPT"
      when: osp_version >= 12 and osp_version <= 13
    - name: Create script to perform necessary container generation (version 12-13)
      shell: |
        egrep ' -e ' {{ deploy_script }} >>/home/{{ uc_user }}/configure_containers.sh
      when: osp_version >= 12 and osp_version <= 13
    - name: Create script to perform necessary container generation (version 12-13)
      blockinfile:
        path: /home/{{ uc_user }}/configure_containers.sh
        block: |2
            --tag-from-label {version}-{release} \
            --output-env-file=/home/{{ uc_user }}/templates/overcloud_images.yaml \
            --output-images-file /home/{{ uc_user }}/registry_images.yaml
        marker: "  # {mark} ANSIBLE BLOCK IMAGES"
      when: osp_version >= 12 and osp_version <= 13
    - name: Add ceph container image lines if needed (version 12-13)
      blockinfile:
        path: /home/{{ uc_user }}/configure_containers.sh
        block: |2
            -e /usr/share/openstack-tripleo-heat-templates/environments/ceph-ansible/ceph-ansible.yaml \
            --set ceph_namespace=registry.access.redhat.com/rhceph \
            --set ceph_image=rhceph-3-rhel7 \
        marker: "  # {mark} ANSIBLE BLOCK CEPH"
        insertbefore: overcloud_images.yaml
      when: include_ceph and ceph_deployment == 'director' and osp_version >= 12 and osp_version <= 13
    - name: Obtain push-destination IP if using a local registry (version 12-13)
      shell: |
        ip a s br-ctlplane | grep inet | head -1 | awk '{print $2}' | awk -F/ '{print $1}'
      register: registry_ip
      when: osp_version >= 12 and osp_version <= 13 and container_registry == 'local'
    - name: Add local namespace information (version 12-13)
      blockinfile:
        path: /home/{{ uc_user }}/configure_containers.sh
        block: |2
            --namespace={{ container_namespace }} \
            --push-destination={{ registry_ip.stdout }}:8787 \
            --prefix={{ container_prefix }}- \
        marker: "  # {mark} ANSIBLE BLOCK LOCAL"
        insertafter: openstack overcloud container image prepare
      when: osp_version >= 12 and osp_version <= 13 and container_registry == 'local'
    - name: Strip out Ansible comments from the script
      shell: |
        sed -i '/ANSIBLE/d' {{ item }}
      with_items:
        - /home/{{ uc_user }}/configure_containers.sh
      when: osp_version >= 12 and osp_version <= 13
    - name: Generate the overcloud image files (version 12-13)
      shell: |
        /home/{{ uc_user }}/configure_containers.sh
      when: osp_version >= 12 and osp_version <=13
    - name: Upload images to local registry (version 12-13)
      shell: |
        openstack overcloud container image upload \
          --config-file /home/{{ uc_user }}/registry_images.yaml \
          --verbose
      become: true
      when: osp_version >= 12 and osp_version <= 13 and container_registry == 'local'
    - name: Check if we have a container repository YAML
      stat:
        path: "{{ stack_templates }}/overcloud_images.yaml"
      register: container_images
    - name: Add overcloud_images.yaml if a container repository exists
      lineinfile:
        path: "{{ deploy_script }}"
        insertbefore: log-file overcloud_deployment.log
        line: '  -e {{ stack_templates }}/overcloud_images.yaml \'
      when: container_images.stat.exists 
    - name: Determine if SSL is enabled on the undercloud (version 13+)
      shell: |
        #!/bin/bash
        
        SSL_ENABLED='false'
        SSL_CERT=''
        
        if [[ -r /home/{{ uc_user }}/undercloud.conf ]]
        then
          SSL_ENABLED=$(grep ^generate_service_certificate /home/{{ uc_user }}/undercloud.conf 2>/dev/null | awk '{print $NF}' | tr '[:upper:]' '[:lower:]')
          if [[ -z "${SSL_ENABLED}" ]]
          then
            SSL_CERT=$(grep ^undercloud_service_certificate /home/{{ uc_user }}/undercloud.conf 2>/dev/null | awk '{print $NF}')
            if [[ ! -f "${SSL_CERT}" ]]
            then
              SSL_ENABLED='false'
            fi
          else
            SSL_CERT=$(sudo ls -tr /etc/pki/ca-trust/source/anchors/*.pem | tail -1)
          fi
        fi
        
        if [[ -f "${SSL_CERT}" ]]
        then
          mkdir -p {{ stack_templates }}/environments/ssl
          cat {{ tripleo_heat_templates }}/environments/ssl/inject-trust-anchor-hiera.yaml | sed -n '/The content of the CA cert goes here/q;p' >{{ stack_templates }}/environments/ssl/inject-trust-anchor-hiera.yaml
          sudo cat ${SSL_CERT} | sed -n '/BEGIN CERTIFICATE/,$p' | sed -n 's/^/        /g;p' >>{{ stack_templates }}/environments/ssl/inject-trust-anchor-hiera.yaml
          sed -i 's/first-ca-name/undercloud/g' {{ stack_templates }}/environments/ssl/inject-trust-anchor-hiera.yaml
        fi
        echo "${SSL_ENABLED}"
      register: undercloud_ssl
    - name: Add undercloud CA if SSL is enabled on the undercloud (version 13+)
      lineinfile:
        path: "{{ deploy_script }}"
        insertbefore: log-file overcloud_deployment.log
        line: '  -e {{ stack_templates }}/environments/ssl/inject-trust-anchor-hiera.yaml \'
      when: undercloud_ssl.stdout == 'true'
    - name: Get list of all NIC config YAML files
      find:
        paths: "{{ stack_templates }}/network/config"
        patterns: '*.yaml'
        recurse: yes
      register: nic_config_directory
    - name: Update relative paths in NIC config
      replace:
        path: "{{ item.path }}"
        regexp: "../../scripts"
        replace: "{{ tripleo_heat_templates }}/network/scripts"
      with_items: "{{ nic_config_directory.files }}"
    - name: Get list of copied template files
      find:
        path: "{{ stack_templates }}"
        patterns: "*.yaml"
        recurse: yes
      register: find_results
    - name: Build stack template list
      set_fact:
        template_files: "{{ template_files }} + [ '{{ item.path }}' ]"
      with_items: "{{ find_results.files }}"
    - name: Update relevant path names (environments)
      replace:
        path: "{{ item }}"
        regexp: '\.\.\/environments'
        replace: "{{ tripleo_heat_templates }}/environments"
      with_items: "{{ template_files }}"
    - name: Update relevant path names (puppet)
      replace:
        path: "{{ item }}"
        regexp: '\.\.\/puppet/'
        replace: "{{ tripleo_heat_templates }}/puppet/"
      with_items: "{{ template_files }}"
    - name: Update relevant path names (network/config)
      replace:
        path: "{{ item }}"
        regexp: '\.\.\/network/config'
        replace: "{{ stack_templates }}/network/config"
      with_items: "{{ template_files }}"
    - name: Update relevant path names (network/ports) (version <13)
      replace:
        path: "{{ item }}"
        regexp: '\.\.\/network/ports'
        replace: "{{ tripleo_heat_templates }}/network/ports"
      with_items: "{{ template_files }}"
      when: osp_version < 13
    - name: Update relevant path names (network) (version 13+)
      replace:
        path: "{{ item }}"
        regexp: '\.\.\/network/'
        replace: "{{ stack_templates }}/network/"
      with_items: "{{ template_files }}"
      when: osp_version >= 13
    - name: Update relevant path names (docker)
      replace:
        path: "{{ item }}"
        regexp: '(\.\./\.\./docker/|\.\./docker/)'
        replace: "{{ tripleo_heat_templates }}/docker/"
      with_items: "{{ template_files }}"
    - name: Strip out Ansible comments from the script
      shell: |
        sed -i '/ANSIBLE/d' {{ item }}
      with_items:
        - "{{ deploy_script }}"
